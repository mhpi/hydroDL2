{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "package_path = '/data/lgl5139/hydro_multimodel/dPLHydro_multimodel'\n",
    "sys.path.append(package_path)\n",
    "\n",
    "\n",
    "from core.data.dataset_loading import get_data_dict, extract_data\n",
    "# dataset_dict, _ = get_data_dict(model.config, train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/data/lgl5139/hydro_multimodel/dPLHydro_multimodel/models/bmi/bmi_config.yaml' #\"bmi_config.yaml\"\n",
    "\n",
    "model = BMIdPLHydroModel()\n",
    "model.initialize(bmi_cfg_filepath=config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = extract_data(model.config)\n",
    "\n",
    "from core.data.dataset_loading import get_data_dict\n",
    "dataset_dict_orig, _ = get_data_dict(model.config, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.43318842, -1.41732912, -1.34593053])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict_orig['inputs_nn_scaled'][1,1,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-07-15 06:25:17][__main__][INFO] - Creating dPLHydro BMI model instance\n",
      "[2024-07-15 06:25:17][__main__][INFO] - INITIALIZING BMI\n",
      "[2024-07-15 06:25:18][__main__][INFO] - Collecting attribute and forcing data\n",
      "[2024-07-15 06:25:18][__main__][INFO] - BEGIN BMI FORWARD: 1 timesteps...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prcp(mm/day) [0.]\n",
      "tmean(C) [-15.08]\n",
      "PET_hargreaves(mm/day) [0.12256418]\n",
      "tmax(C) [-10.2]\n",
      "tmin(C) [-19.96]\n",
      "prcp(mm/day) [0.0]\n",
      "tmean(C) [-15.08]\n",
      "PET_hargreaves(mm/day) [0.12256418168544769]\n",
      "[[[  0.         -15.08         0.12256418]\n",
      "  [  0.         -15.08         0.12256418]\n",
      "  [  0.         -15.08         0.12256418]\n",
      "  [  0.         -15.08         0.12256418]\n",
      "  [  0.         -15.08         0.12256418]]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a testing script for running a dPL, physics-informed machine learning\n",
    "model BMI that is NextGen framework and NOAA OWP operation-ready.\n",
    "\n",
    "Note:\n",
    "- The current setup only passes CAMELS (671 basins) data to the BMI. For\n",
    "    different datasets, `.set_value()` mappings must be modeified to the respective\n",
    "    forcing + attribute key values.\n",
    "\"\"\"\n",
    "import os\n",
    "from ruamel.yaml import YAML\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s][%(name)s][%(levelname)s] - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "from core.data.dataset_loading import get_data_dict\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "################## Initialize the BMI ##################\n",
    "# Path to BMI config.\n",
    "config_path = '/data/lgl5139/hydro_multimodel/dPLHydro_multimodel/models/bmi/bmi_config.yaml' #\"bmi_config.yaml\"\n",
    "\n",
    "# Create instance of BMI model.\n",
    "log.info(\"Creating dPLHydro BMI model instance\")\n",
    "model = BMIdPLHydroModel()\n",
    "\n",
    "# [CONTROL FUNCTION] Initialize the BMI.\n",
    "log.info(f\"INITIALIZING BMI\")\n",
    "model.initialize(bmi_cfg_filepath=config_path)\n",
    "\n",
    "\n",
    "################## Get test data ##################\n",
    "log.info(f\"Collecting attribute and forcing data\")\n",
    "\n",
    "# TODO: Adapt this PMI data loader to be more-BMI friendly, less a function iceberg.\n",
    "# dataset_dict, _ = get_data_dict(model.config, train=False)\n",
    "\n",
    "# Fixing typo in CAMELS dataset: 'geol_porostiy'.\n",
    "# (Written into config somewhere inside get_data_dict...)\n",
    "# var_c_nn = model.config['observations']['var_c_nn']\n",
    "# if 'geol_porostiy' in var_c_nn:\n",
    "#     model.config['observations']['var_c_nn'][var_c_nn.index('geol_porostiy')] = 'geol_porosity'\n",
    "if 'geol_porostiy' in dataset_dict['c_all'].keys():\n",
    "    dataset_dict['c_all']['geol_porosity'] = dataset_dict['c_all'].pop('geol_porostiy')\n",
    "\n",
    "\n",
    "################## Forward model for 1 or multiple timesteps ##################\n",
    "# n_timesteps = dataset_dict['inputs_nn_scaled'].shape[0]\n",
    "n_timesteps = 1  # debug\n",
    "n_basins = 1\n",
    "\n",
    "log.info(f\"BEGIN BMI FORWARD: {n_timesteps} timesteps...\")\n",
    "\n",
    "# TODO: write a timestep handler/translator so we can pull out\n",
    "# forcings/attributes for the specific timesteps we want streamflow predictions for.\n",
    "forcing_list = list(\n",
    "    dict.fromkeys(model.config['observations']['var_t_nn'] + model.config['observations']['var_t_hydro_model'])\n",
    "    )\n",
    "attribute_list = list(\n",
    "    dict.fromkeys(model.config['observations']['var_c_nn'] + model.config['observations']['var_c_hydro_model'])\n",
    "    )\n",
    "\n",
    "# Loop through and return streamflow at each timestep.\n",
    "for t in range(n_timesteps):\n",
    "    # NOTE: for each timestep in this loop, the data assignments below are of\n",
    "    # arrays of basins. e.g., forcings['key'].shape = (1, # basins)\n",
    "\n",
    "    ################## Map forcings + attributes into BMI ##################\n",
    "    # Set forcings...\n",
    "    for var in model.config['forcing_names']:\n",
    "        standard_name = model._var_name_map_short_first[var]\n",
    "        print(var, dataset_dict['x_all'][var][t, :n_basins])\n",
    "        model.set_value(standard_name, dataset_dict['x_all'][var][t, :n_basins])\n",
    "    \n",
    "    # # Set attributes...\n",
    "    # for var in model.config['attribute_names']:\n",
    "    #     standard_name = model._var_name_map_short_first[var]\n",
    "    #     model.set_value(standard_name, dataset_dict['c_all'][var][:n_basins])\n",
    "\n",
    "    # [CONTROL FUNCTION] Update the model at all basins for one timestep.\n",
    "    model.update()\n",
    "    # print(f\"Streamflow at time {model.t} is {model.streamflow_cms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-15.08])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['x_all']['tmean(C)'][t, :n_basins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.69341599, -2.39613028, -1.48692608]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict_orig['inputs_nn_scaled'][0,:n_basins,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    time_steps = len(self._values[self._var_name_map_short_first[self.config['observations']['var_t_nn'][0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 38)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['inputs_nn_scaled'][1,:n_basins,:].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._values[standard_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((2, 3))\n",
    "\n",
    "x[:,0] = np.array([model._values['atmosphere_water__liquid_equivalent_precipitation_rate']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.18678652, 0.        , 0.        ],\n",
       "       [1.43318842, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.18678652],\n",
       "       [1.43318842]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([model._values['atmosphere_water__liquid_equivalent_precipitation_rate']]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(1, 0), dtype=float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BMI wrapper for interfacing dPL hydrology models with NOAA OWP NextGen framework.\n",
    "\"\"\"\n",
    "# Need this to get external packages like conf.config.\n",
    "import sys\n",
    "package_path = '/data/lgl5139/hydro_multimodel/dPLHydro_multimodel'\n",
    "sys.path.append(package_path)\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Optional, Any, Dict, Union\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "from ruamel.yaml import YAML\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from bmipy import Bmi\n",
    "from conf.config import Config\n",
    "from models.model_handler import ModelHandler\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from pydantic import ValidationError\n",
    "from core.data import take_sample_test\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "class BMIdPLHydroModel(Bmi):\n",
    "    \"\"\"\n",
    "    Run forward with BMI for a trained differentiable hydrology model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Create a dPLHydro model BMI ready for initialization.\n",
    "        \"\"\"\n",
    "        super(BMIdPLHydroModel, self).__init__()\n",
    "        start_time = time.time()\n",
    "\n",
    "        self._model = None\n",
    "        self._initialized = False\n",
    "\n",
    "        self._start_time = 0.0\n",
    "        self._values = {}\n",
    "        self._end_time = np.finfo(float).max\n",
    "        self.var_array_lengths = 1\n",
    "\n",
    "        self.bmi_process_time = 0\n",
    "\n",
    "\n",
    "        # Required, static attributes of the model\n",
    "        _att_map = {\n",
    "        'model_name':         \"Differentiable Parameter Learning Hydrology BMI\",\n",
    "        'version':            '1.0',\n",
    "        'author_name':        'MHPI',\n",
    "        'time_units':         'days',\n",
    "        }\n",
    "        \n",
    "        # Input forcing/attribute CSDMS Standard Names.\n",
    "        self._input_var_names = [\n",
    "            ############## Forcings ##############\n",
    "            'atmosphere_water__liquid_equivalent_precipitation_rate',\n",
    "            'land_surface_air__temperature',\n",
    "            'land_surface_air__max_of_temperature',  # custom name\n",
    "            'land_surface_air__min_of_temperature',  # custom name\n",
    "            'land_surface_water__potential_evaporation_volume_flux',  # check name,\n",
    "            ############## Attributes ##############\n",
    "            'atmosphere_water__daily_mean_of_liquid_equivalent_precipitation_rate',\n",
    "            'land_surface_water__daily_mean_of_potential_evaporation_flux',\n",
    "            'p_seasonality',  # custom name\n",
    "            'atmosphere_water__precipitation_falling_as_snow_fraction',\n",
    "            'ratio__mean_potential_evapotranspiration__mean_precipitation',\n",
    "            'atmosphere_water__frequency_of_high_precipitation_events',\n",
    "            'atmosphere_water__mean_duration_of_high_precipitation_events',\n",
    "            'atmosphere_water__precipitation_frequency',\n",
    "            'atmosphere_water__low_precipitation_duration',\n",
    "            'basin__mean_of_elevation',\n",
    "            'basin__mean_of_slope',\n",
    "            'basin__area',\n",
    "            'land_vegetation__forest_area_fraction',\n",
    "            'land_vegetation__max_monthly_mean_of_leaf-area_index',\n",
    "            'land_vegetation__diff_max_min_monthly_mean_of_leaf-area_index',\n",
    "            'land_vegetation__max_monthly_mean_of_green_vegetation_fraction',\n",
    "            'land_vegetation__diff__max_min_monthly_mean_of_green_vegetation_fraction',\n",
    "            'region_state_land~covered__area_fraction',  # custom name\n",
    "            'region_state_land~covered__area',  # custom name\n",
    "            'root__depth',  # custom name\n",
    "            'soil_bedrock_top__depth__pelletier',\n",
    "            'soil_bedrock_top__depth__statsgo',\n",
    "            'soil__porosity',\n",
    "            'soil__saturated_hydraulic_conductivity',\n",
    "            'maximum_water_content',\n",
    "            'soil_sand__volume_fraction',\n",
    "            'soil_silt__volume_fraction', \n",
    "            'soil_clay__volume_fraction',\n",
    "            'geol_1st_class',  # custom name\n",
    "            'geol_1st_class__fraction',  # custom name\n",
    "            'geol_2nd_class',  # custom name\n",
    "            'geol_2nd_class__fraction',  # custom name\n",
    "            'basin__carbonate_rocks_area_fraction',\n",
    "            'soil_active-layer__porosity',  # check name\n",
    "            'bedrock__permeability'\n",
    "        ]\n",
    "\n",
    "        # Output variable names (CSDMS standard names)\n",
    "        self._output_var_names = ['land_surface_water__runoff_volume_flux']\n",
    "\n",
    "        # Map CSDMS Standard Names to the model's internal variable names (For CAMELS).\n",
    "        self._var_name_units_map = {\n",
    "            ############## Forcings ##############\n",
    "            'atmosphere_water__liquid_equivalent_precipitation_rate':['prcp(mm/day)', 'mm d-1'],\n",
    "            'land_surface_air__temperature':['tmean(C)','degC'],\n",
    "            'land_surface_air__max_of_temperature':['tmax(C)', 'degC'],  # custom name\n",
    "            'land_surface_air__min_of_temperature':['tmin(C)', 'degC'],  # custom name\n",
    "            'land_surface_water__potential_evaporation_volume_flux':['PET_hargreaves(mm/day)', 'mm d-1'],  # check name\n",
    "            ############## Attributes ##############\n",
    "            'atmosphere_water__daily_mean_of_liquid_equivalent_precipitation_rate':['p_mean','mm d-1'],\n",
    "            'land_surface_water__daily_mean_of_potential_evaporation_flux':['pet_mean','mm d-1'],\n",
    "            'p_seasonality':['p_seasonality', '-'],  # custom name\n",
    "            'atmosphere_water__precipitation_falling_as_snow_fraction':['frac_snow','-'],\n",
    "            'ratio__mean_potential_evapotranspiration__mean_precipitation':['aridity','-'],\n",
    "            'atmosphere_water__frequency_of_high_precipitation_events':['high_prec_freq','d yr-1'],\n",
    "            'atmosphere_water__mean_duration_of_high_precipitation_events':['high_prec_dur','d'],\n",
    "            'atmosphere_water__precipitation_frequency':['low_prec_freq','d yr-1'],\n",
    "            'atmosphere_water__low_precipitation_duration':['low_prec_dur','d'],\n",
    "            'basin__mean_of_elevation':['elev_mean','m'],\n",
    "            'basin__mean_of_slope':['slope_mean','m km-1'],\n",
    "            'basin__area':['area_gages2','km2'],\n",
    "            'land_vegetation__forest_area_fraction':['frac_forest','-'],\n",
    "            'land_vegetation__max_monthly_mean_of_leaf-area_index':['lai_max','-'],\n",
    "            'land_vegetation__diff_max_min_monthly_mean_of_leaf-area_index':['lai_diff','-'],\n",
    "            'land_vegetation__max_monthly_mean_of_green_vegetation_fraction':['gvf_max','-'],\n",
    "            'land_vegetation__diff__max_min_monthly_mean_of_green_vegetation_fraction':['gvf_diff','-'],\n",
    "            'region_state_land~covered__area_fraction':['dom_land_cover_frac', 'percent'],  # custom name\n",
    "            'region_state_land~covered__area':['dom_land_cover', '-'],  # custom name\n",
    "            'root__depth':['root_depth_50', '-'],  # custom name\n",
    "            'soil_bedrock_top__depth__pelletier':['soil_depth_pelletier','m'],\n",
    "            'soil_bedrock_top__depth__statsgo':['soil_depth_statsgo','m'],\n",
    "            'soil__porosity':['soil_porosity','-'],\n",
    "            'soil__saturated_hydraulic_conductivity':['soil_conductivity','cm hr-1'],\n",
    "            'maximum_water_content':['max_water_content','m'],\n",
    "            'soil_sand__volume_fraction':['sand_frac','percent'],\n",
    "            'soil_silt__volume_fraction':['silt_frac','percent'], \n",
    "            'soil_clay__volume_fraction':['clay_frac','percent'],\n",
    "            'geol_1st_class':['geol_1st_class', '-'],  # custom name\n",
    "            'geol_1st_class__fraction':['glim_1st_class_frac', '-'],  # custom name\n",
    "            'geol_2nd_class':['geol_2nd_class', '-'],  # custom name\n",
    "            'geol_2nd_class__fraction':['glim_2nd_class_frac', '-'],  # custom name\n",
    "            'basin__carbonate_rocks_area_fraction':['carbonate_rocks_frac','-'],\n",
    "            'soil_active-layer__porosity':['geol_porosity', '-'],  # check name\n",
    "            'bedrock__permeability':['geol_permeability','m2'],\n",
    "            'drainage__area':['DRAIN_SQKM', 'km2'],  # custom name\n",
    "            'land_surface__latitude':['lat','degrees'],\n",
    "            ############## Outputs ##############\n",
    "            'land_surface_water__runoff_volume_flux':['streamflow_cms','m3 s-1']\n",
    "            }\n",
    "        \n",
    "        # Keep running total of BMI runtime.\n",
    "        self.bmi_process_time += time.time() - start_time\n",
    "    \n",
    "    def initialize(self, bmi_cfg_filepath: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        (BMI Control function) Initialize the dPLHydro model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bmi_cfg_filepath : str, optional\n",
    "            Path to the BMI configuration file.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Read in BMI configurations, add some additional config fields.\n",
    "        self.initialize_config(bmi_cfg_filepath)\n",
    "        self.config['forcing_names'] = list(\n",
    "            dict.fromkeys(model.config['observations']['var_t_nn'] + model.config['observations']['var_t_hydro_model'])\n",
    "        )\n",
    "        self.config['attribute_names'] = list(\n",
    "            dict.fromkeys(model.config['observations']['var_c_nn'] + model.config['observations']['var_c_hydro_model'])\n",
    "        )\n",
    "\n",
    "        # Initialize inputs and outputs.\n",
    "        for var in list(self._var_name_units_map.keys()):\n",
    "            self._values[var] = []\n",
    "            # setattr(self, var, 0)\n",
    "        \n",
    "        # Make lookup tables (Peckham et al.).\n",
    "        self._var_name_map_long_first = {\n",
    "            long_name:self._var_name_units_map[long_name][0] for \\\n",
    "            long_name in self._var_name_units_map.keys()\n",
    "            }\n",
    "        self._var_name_map_short_first = {\n",
    "            self._var_name_units_map[long_name][0]:long_name for \\\n",
    "            long_name in self._var_name_units_map.keys()}\n",
    "        self._var_units_map = {\n",
    "            long_name:self._var_name_units_map[long_name][1] for \\\n",
    "            long_name in self._var_name_units_map.keys()\n",
    "        }\n",
    "\n",
    "        # Set a simulation start time and gettimestep size.\n",
    "        self.current_time = self._start_time\n",
    "        self._time_step_size = self.config['time_step_delta']\n",
    "\n",
    "        # Load a trained model.\n",
    "        self._model = ModelHandler(self.config).to(self.config['device'])\n",
    "        self._initialized = True\n",
    "\n",
    "        # Intialize dataset (NOTE: move this externally).\n",
    "        # self._get_data_dict()\n",
    "\n",
    "        # Keep running total of BMI runtime.\n",
    "        self.bmi_process_time += time.time() - start_time\n",
    "\n",
    "    def update(self) -> None:\n",
    "        \"\"\"\n",
    "        (BMI Control function) Advance model state by one time step.\n",
    "\n",
    "        Note: Models should be trained standalone with dPLHydro_PMI first before forward predictions with this BMI.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        self.current_time += self._time_step_size \n",
    "        \n",
    "        self._values_to_dict()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # # Assembles input values into Torch tensor and takes slice for model forward.\n",
    "        # self.get_tensor_slice()\n",
    "        # self.output = self._model.forward(self.input_tensor)\n",
    "\n",
    "        # # Keep running total of BMI runtime.\n",
    "        # self.bmi_process_time += time.time() - start_time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _get_data_dict(self) -> None:\n",
    "        \"\"\"\n",
    "        Construct data dictionary from BMI input data.\n",
    "\n",
    "        iS, iE: arrays of start and end pairs of basin indicies for batching.\n",
    "        \"\"\"\n",
    "        dataset_dict, self.config = self._values_to_dict()\n",
    "\n",
    "\n",
    "\n",
    "    def update_frac(self, time_frac: float) -> None:\n",
    "        \"\"\"\n",
    "        Update model by a fraction of a time step.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        time_frac : float\n",
    "            Fraction fo a time step.\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"Warning: This model is trained to make predictions on one day timesteps.\")\n",
    "        time_step = self.get_time_step()\n",
    "        self._time_step_size = self._time_step_size * time_frac\n",
    "        self.update()\n",
    "        self._time_step_size = time_step\n",
    "\n",
    "    def update_until(self, end_time: float) -> None:\n",
    "        \"\"\"\n",
    "        (BMI Control function) Update model until a particular time.\n",
    "        Note: Models should be trained standalone with dPLHydro_PMI first before forward predictions with this BMI.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        end_time : float\n",
    "            Time to run model until.\n",
    "        \"\"\"\n",
    "        n_steps = (end_time - self.get_current_time()) / self.get_time_step()\n",
    "\n",
    "        for _ in range(int(n_steps)):\n",
    "            self.update()\n",
    "        self.update_frac(n_steps - int(n_steps))\n",
    "\n",
    "    def finalize(self) -> None:\n",
    "        \"\"\"\n",
    "        (BMI Control function) Finalize model.\n",
    "        \"\"\"\n",
    "        # TODO: Force destruction of ESMF and other objects when testing is done\n",
    "        # to save space.\n",
    "\n",
    "        self._model = None\n",
    "\n",
    "    def array_to_tensor(self) -> None:\n",
    "        \"\"\"\n",
    "        Converts input values into Torch tensor object to be read by model. \n",
    "        \"\"\"  \n",
    "        raise NotImplementedError(\"array_to_tensor\")\n",
    "    \n",
    "    def tensor_to_array(self) -> None:\n",
    "        \"\"\"\n",
    "        Converts model output Torch tensor into date + gradient arrays to be\n",
    "        passed out of BMI for backpropagation, loss, optimizer tuning.\n",
    "        \"\"\"  \n",
    "        raise NotImplementedError(\"tensor_to_array\")\n",
    "    \n",
    "    def get_tensor_slice(self):\n",
    "        \"\"\"\n",
    "        Get tensor of input data for a single timestep.\n",
    "        \"\"\"\n",
    "        # sample_dict = take_sample_test(self.bmi_config, self.dataset_dict)\n",
    "        # self.input_tensor = torch.Tensor()\n",
    "    \n",
    "        raise NotImplementedError(\"get_tensor_slice\")\n",
    "\n",
    "    # ------------------ Finished up to here ------------------\n",
    "    # ---------------------------------------------------------\n",
    "    def get_var_type(self, var_name):\n",
    "        \"\"\"\n",
    "        Data type of variable.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        var_name : str\n",
    "            Name of variable as CSDMS Standard Name.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Data type.\n",
    "        \"\"\"\n",
    "        return str(self.get_value_ptr(var_name).dtype)\n",
    "\n",
    "    def get_var_units(self, var_name):\n",
    "        \"\"\"Get units of variable.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        var_name : str\n",
    "            Name of variable as CSDMS Standard Name.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Variable units.\n",
    "        \"\"\"\n",
    "        return self._var_units[var_name]\n",
    "\n",
    "    def get_var_nbytes(self, var_name):\n",
    "        \"\"\"Get units of variable.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        var_name : str\n",
    "            Name of variable as CSDMS Standard Name.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Size of data array in bytes.\n",
    "        \"\"\"\n",
    "        return self.get_value_ptr(var_name).nbytes\n",
    "\n",
    "    def get_var_itemsize(self, name):\n",
    "        return np.dtype(self.get_var_type(name)).itemsize\n",
    "\n",
    "    def get_var_location(self, name):\n",
    "        return self._var_loc[name]\n",
    "\n",
    "    def get_var_grid(self, var_name):\n",
    "        \"\"\"Grid id for a variable.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        var_name : str\n",
    "            Name of variable as CSDMS Standard Name.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Grid id.\n",
    "        \"\"\"\n",
    "        # for grid_id, var_name_list in self._grids.items():\n",
    "        #     if var_name in var_name_list:\n",
    "        #         return grid_id\n",
    "        raise NotImplementedError(\"get_var_grid\")\n",
    "\n",
    "    def get_grid_rank(self, grid_id):\n",
    "        \"\"\"Rank of grid.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        grid_id : int\n",
    "            Identifier of a grid.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Rank of grid.\n",
    "        \"\"\"\n",
    "        # return len(self._model.shape)\n",
    "        raise NotImplementedError(\"get_grid_rank\")\n",
    "\n",
    "\n",
    "    def get_grid_size(self, grid_id):\n",
    "        \"\"\"Size of grid.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        grid_id : int\n",
    "            Identifier of a grid.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Size of grid.\n",
    "        \"\"\"\n",
    "        # return int(np.prod(self._model.shape))\n",
    "        raise NotImplementedError(\"get_grid_size\")\n",
    "\n",
    "\n",
    "    def get_value_ptr(self, var_name: str) -> np.ndarray:\n",
    "        \"\"\"Reference to values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        var_name : str\n",
    "            Name of variable as CSDMS Standard Name.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array_like\n",
    "            Value array.\n",
    "        \"\"\"\n",
    "        if var_name not in self._values.keys():\n",
    "            raise ValueError(f\"No known variable in BMI model: {var_name}\")\n",
    "        \n",
    "        return self._values[var_name]\n",
    "\n",
    "    def get_value(self, var_name, dest):\n",
    "        \"\"\"Copy of values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        var_name : str\n",
    "            Name of variable as CSDMS Standard Name.\n",
    "        dest : ndarray\n",
    "            A numpy array into which to place the values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array_like\n",
    "            Copy of values.\n",
    "        \"\"\"\n",
    "        dest[:] = self.get_value_ptr(var_name).flatten()\n",
    "        return dest\n",
    "\n",
    "    def get_value_at_indices(self, var_name, dest, indices):\n",
    "        \"\"\"Get values at particular indices.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        var_name : str\n",
    "            Name of variable as CSDMS Standard Name.\n",
    "        dest : ndarray\n",
    "            A numpy array into which to place the values.\n",
    "        indices : array_like\n",
    "            Array of indices.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array_like\n",
    "            Values at indices.\n",
    "        \"\"\"\n",
    "        dest[:] = self.get_value_ptr(var_name).take(indices)\n",
    "        return dest\n",
    "\n",
    "    def set_value(self, var_name, values: np.ndarray):\n",
    "        \"\"\"Set model values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        var_name : str\n",
    "            Name of variable as CSDMS Standard Name.\n",
    "        values : array_like\n",
    "            Array of new values.\n",
    "        \"\"\"\n",
    "        if not isinstance(values, (np.ndarray, list, tuple)):\n",
    "            values = np.array([values])\n",
    "\n",
    "        val = self.get_value_ptr(var_name)\n",
    "\n",
    "        # val = values.reshape(val.shape)\n",
    "        val[:] = values\n",
    "\n",
    "    def set_value_at_indices(self, name, inds, src):\n",
    "        \"\"\"Set model values at particular indices.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        var_name : str\n",
    "            Name of variable as CSDMS Standard Name.\n",
    "        src : array_like\n",
    "            Array of new values.\n",
    "        indices : array_like\n",
    "            Array of indices.\n",
    "        \"\"\"\n",
    "        val = self.get_value_ptr(name)\n",
    "        val.flat[inds] = src\n",
    "\n",
    "    def get_component_name(self):\n",
    "        \"\"\"Name of the component.\"\"\"\n",
    "        return self._name\n",
    "\n",
    "    def get_input_item_count(self):\n",
    "        \"\"\"Get names of input variables.\"\"\"\n",
    "        return len(self._input_var_names)\n",
    "\n",
    "    def get_output_item_count(self):\n",
    "        \"\"\"Get names of output variables.\"\"\"\n",
    "        return len(self._output_var_names)\n",
    "\n",
    "    def get_input_var_names(self):\n",
    "        \"\"\"Get names of input variables.\"\"\"\n",
    "        return self._input_var_names\n",
    "\n",
    "    def get_output_var_names(self):\n",
    "        \"\"\"Get names of output variables.\"\"\"\n",
    "        return self._output_var_names\n",
    "\n",
    "    def get_grid_shape(self, grid_id, shape):\n",
    "        \"\"\"Number of rows and columns of uniform rectilinear grid.\"\"\"\n",
    "        # var_name = self._grids[grid_id][0]\n",
    "        # shape[:] = self.get_value_ptr(var_name).shape\n",
    "        # return shape\n",
    "        raise NotImplementedError(\"get_grid_shape\")\n",
    "\n",
    "    def get_grid_spacing(self, grid_id, spacing):\n",
    "        \"\"\"Spacing of rows and columns of uniform rectilinear grid.\"\"\"\n",
    "        # spacing[:] = self._model.spacing\n",
    "        # return spacing\n",
    "        raise NotImplementedError(\"get_grid_spacing\")\n",
    "\n",
    "    def get_grid_origin(self, grid_id, origin):\n",
    "        \"\"\"Origin of uniform rectilinear grid.\"\"\"\n",
    "        # origin[:] = self._model.origin\n",
    "        # return origin\n",
    "        raise NotImplementedError(\"get_grid_origin\")\n",
    "\n",
    "    def get_grid_type(self, grid_id):\n",
    "        \"\"\"Type of grid.\"\"\"\n",
    "        # return self._grid_type[grid_id]\n",
    "        raise NotImplementedError(\"get_grid_type\")\n",
    "\n",
    "    def get_start_time(self):\n",
    "        \"\"\"Start time of model.\"\"\"\n",
    "        return self._start_time\n",
    "\n",
    "    def get_end_time(self):\n",
    "        \"\"\"End time of model.\"\"\"\n",
    "        return self._end_time\n",
    "\n",
    "    def get_current_time(self):\n",
    "        return self._current_time\n",
    "\n",
    "    def get_time_step(self):\n",
    "        return self._time_step_size\n",
    "\n",
    "    def get_time_units(self):\n",
    "        return self._time_units\n",
    "\n",
    "    def get_grid_edge_count(self, grid):\n",
    "        raise NotImplementedError(\"get_grid_edge_count\")\n",
    "\n",
    "    def get_grid_edge_nodes(self, grid, edge_nodes):\n",
    "        raise NotImplementedError(\"get_grid_edge_nodes\")\n",
    "\n",
    "    def get_grid_face_count(self, grid):\n",
    "        raise NotImplementedError(\"get_grid_face_count\")\n",
    "\n",
    "    def get_grid_face_nodes(self, grid, face_nodes):\n",
    "        raise NotImplementedError(\"get_grid_face_nodes\")\n",
    "\n",
    "    def get_grid_node_count(self, grid):\n",
    "        \"\"\"Number of grid nodes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        grid : int\n",
    "            Identifier of a grid.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Size of grid.\n",
    "        \"\"\"\n",
    "        # return self.get_grid_size(grid)\n",
    "        raise NotImplementedError(\"get_grid_node_count\")\n",
    "\n",
    "        \n",
    "\n",
    "    def get_grid_nodes_per_face(self, grid, nodes_per_face):\n",
    "        raise NotImplementedError(\"get_grid_nodes_per_face\")\n",
    "\n",
    "    def get_grid_face_edges(self, grid, face_edges):\n",
    "        raise NotImplementedError(\"get_grid_face_edges\")\n",
    "\n",
    "    def get_grid_x(self, grid, x):\n",
    "        raise NotImplementedError(\"get_grid_x\")\n",
    "\n",
    "    def get_grid_y(self, grid, y):\n",
    "        raise NotImplementedError(\"get_grid_y\")\n",
    "\n",
    "    def get_grid_z(self, grid, z):\n",
    "        raise NotImplementedError(\"get_grid_z\")\n",
    "\n",
    "    def initialize_config(self, config_path: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Check that config_path is valid path and convert config into a\n",
    "        dictionary object.\n",
    "        \"\"\"\n",
    "        config_path = Path(config_path).resolve()\n",
    "        \n",
    "        if not config_path:\n",
    "            raise RuntimeError(\"No BMI configuration path provided.\")\n",
    "        elif not config_path.is_file():\n",
    "            raise RuntimeError(f\"BMI configuration not found at path {config_path}.\")\n",
    "        else:\n",
    "            with config_path.open('r') as f:\n",
    "                self.config = yaml.safe_load(f)\n",
    "    \n",
    "\n",
    "        # USE BELOW FOR HYDRA + OMEGACONF:\n",
    "        # try:\n",
    "        #     config_dict: Union[Dict[str, Any], Any] = OmegaConf.to_container(\n",
    "        #         cfg, resolve=True\n",
    "        #     )\n",
    "        #     config = Config(**config_dict)\n",
    "        # except ValidationError as e:\n",
    "        #     log.exception(e)\n",
    "        #     raise e\n",
    "        # return config, config_dict\n",
    "\n",
    "\n",
    "    def _values_to_dict(self) -> None:\n",
    "        \"\"\"\n",
    "        Take CSDMS Standard Name-mapped forcings + attributes and construct data\n",
    "        dictionary for NN and physics model.\n",
    "\n",
    "        Basically, trying to replicate output from core.data.get_data_dict().\n",
    "        \"\"\"\n",
    "        n_basins = len(self._values[self._var_name_map_short_first[self.config['observations']['var_t_nn'][0]]])\n",
    "        x_nn = np.zeros((n_basins, len(self.config['forcing_names'])))\n",
    "        # c_nn = np.zeros((n_basins, len(self.config['attribute_names'])))\n",
    "\n",
    "\n",
    "        ### First get scaled inputs for the NN.\n",
    "        for i, var in enumerate(self.config['observations']['var_t_nn']):\n",
    "            standard_name = self._var_name_map_short_first[var]\n",
    "            print(var, self._values[standard_name])\n",
    "            x_nn[:, :, i] = np.array([self._values[standard_name]])\n",
    "\n",
    "        print(x_nn)\n",
    "\n",
    "\n",
    "\n",
    "        ### Get physics model forcing inputs.\n",
    "        ### Get physics model attribute inputs.\n",
    "\n",
    "\n",
    "\n",
    "        # for i, var in enumerate(self.config['observations']['var_t_nn']):\n",
    "        #     standard_name = self._var_name_map_short_first[var]\n",
    "        #     # NOTE: Using _values is a bit hacky. Should use get_values I think.    \n",
    "        #     x_nn[:, :, i] = np.array([self._values[standard_name]])\n",
    "        \n",
    "        # for i, var in enumerate(self.config['observations']['var_c_nn']):\n",
    "        #     standard_name = self._var_name_map_short_first[var]\n",
    "        #     # NOTE: Using _values is a bit hacky. Should use get_values I think.    \n",
    "        #     c_nn[:, i] = np.array([self._values[standard_name]])\n",
    "\n",
    "        # for i, var in enumerate(self.config['observations']['var_t_hydro_model']):\n",
    "        #     standard_name = self._var_name_map_short_first[var]\n",
    "        #     # NOTE: Using _values is a bit hacky. Should use get_values I think.    \n",
    "        #     x_hydro_model[:, i] = np.array([self._values[standard_name]])\n",
    "\n",
    "        # for i, var in enumerate(self.config['observations']['var_c_hydro_model']):\n",
    "        #     standard_name = self._var_name_map_short_first[var]\n",
    "        #     # NOTE: Using _values is a bit hacky. Should use get_values I think.    \n",
    "        #     c_hydro_model[:, i] = np.array([self._values[standard_name]])\n",
    "\n",
    "            \n",
    "        # # c_nn = np.repeat(np.expand_dims(c_nn, 0), x_nn.shape[0], axis=0)\n",
    "        # print(x_nn, \"-----\")\n",
    "        # print(c_nn, \"-----\")\n",
    "        # print(np.concatenate((x_nn, c_nn), axis=1))\n",
    "        # # print(np.concatenate((x_nn, c_nn),axis=1))\n",
    "        \n",
    "        # dataset_dict = {\n",
    "        #     'inputs_nn_scaled': np.concatenate((x_nn, c_nn), axis=1),\n",
    "        #     'x_hydro_model': x_hydro_model,\n",
    "        #     'c_hydro_model': c_hydro_model\n",
    "        # }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example BMI Forward\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "# import data_tools\n",
    "from pathlib import Path\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# This is the BMI LSTM that we will be running\n",
    "import lstm.bmi_lstm as bmi_lstm\n",
    "\n",
    "USE_PATH = True  # (SDP; also set in bmi_lstm.py.)\n",
    "# run_dir = './extern/lstm_py/'  # (SDP)\n",
    "run_dir = './'\n",
    "cfg_file  = run_dir + 'bmi_config_files/01022500_hourly_slope_mean_precip_temp.yml'\n",
    "data_file = run_dir + 'data/usgs-streamflow-nldas_hourly.nc'\n",
    "    \n",
    "def execute():\n",
    "    # creating an instance of an LSTM model\n",
    "    print('Creating an instance of an BMI_LSTM model object...')\n",
    "    model = bmi_lstm.bmi_LSTM()\n",
    "\n",
    "    # Initializing the BMI\n",
    "    print('Initializing the BMI...')\n",
    "    # Argument to initialize should be type string, not Path object. (SDP)\n",
    "    # Better to use path inside initialize(). (SDP)\n",
    "    ### model.initialize(bmi_cfg_file=Path('./bmi_config_files/01022500_A.yml'))\n",
    "    model.initialize(bmi_cfg_file=cfg_file)  # (SDP)\n",
    "\n",
    "    # Get input data that matches the LSTM test runs\n",
    "    print('Get input data that matches the LSTM test runs...')\n",
    "\n",
    "    if (USE_PATH):\n",
    "        sample_data = Dataset(Path( data_file ), 'r')\n",
    "    else:\n",
    "        sample_data = Dataset( data_file, 'r' )  # SDP\n",
    "\n",
    "        \n",
    "    # Now loop through the inputs, set the forcing values, and update the model\n",
    "    print('Loop through the inputs, set the forcing values, and update the model...')\n",
    "    precip_data = sample_data['total_precipitation'][3].data\n",
    "    n_forcings = precip_data.size\n",
    "    temp_data = sample_data['temperature'][3].data\n",
    "\n",
    "    for k in range(n_forcings):\n",
    "    #for precip, temp in list(),\n",
    "        \n",
    "        precip = precip_data[k]\n",
    "        temp = temp_data[k]                    \n",
    "        model.set_value('atmosphere_water__liquid_equivalent_precipitation_rate',precip)\n",
    "        model.set_value('land_surface_air__temperature',temp)\n",
    "        print('  temperature and precipitation are set to {:.2f} and {:.2f}'.format(temp, precip))\n",
    "        #print('  temperature and precipitation are set to {:.2f} and {:.2f}'.format(model.temperature, model.precip))\n",
    "        model.update()\n",
    "        print('  streamflow (CMS) at time {} is {:.2f}'.format(model.t, model.streamflow_cms))\n",
    "        #### print('  streamflow (CFS) at time {} is {:.2f}'.format(model.t, model.streamflow_cfs))\n",
    "\n",
    "        if model.t > 100:\n",
    "            print('Stopping the loop...')\n",
    "            break\n",
    "\n",
    "    # Finalizing the BMI\n",
    "    print('Finalizing the BMI...')\n",
    "    model.finalize()\n",
    "    print('Finished.')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mulhydrodl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
